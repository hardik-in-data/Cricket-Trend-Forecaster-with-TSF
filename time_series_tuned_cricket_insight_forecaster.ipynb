{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "df_bowling = pd.read_csv(\"test_Bowling_Card.csv\", low_memory=False)\n",
    "df_batting = pd.read_csv(\"test_Batting_Card.csv\", low_memory=False)\n",
    "df_players = pd.read_csv(\"players_info.csv\", low_memory=False)\n",
    "df_matches = pd.read_csv(\"test_Matches_Data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Basic Info\n",
    "\n",
    "df_bowling.info()\n",
    "# df_batting.info()\n",
    "# df_players.info()\n",
    "# df_matches.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 10 Random Rows\n",
    "\n",
    "df_bowling.sample(n=10)\n",
    "# df_batting.sample(n=10)\n",
    "# df_players.sample(n=10)\n",
    "# df_matches.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "\n",
    "print(\"\\nMissing Values in Bowling Data:\")\n",
    "print(df_bowling.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Batting Data:\")\n",
    "print(df_batting.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Players Data:\")\n",
    "print(df_players.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Matches Data:\")\n",
    "print(df_matches.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics\n",
    "\n",
    "print(\"\\nBowling Data Summary:\")\n",
    "print(df_bowling.describe())\n",
    "\n",
    "print(\"\\nBatting Data Summary:\")\n",
    "print(df_batting.describe())\n",
    "\n",
    "print(\"\\nPlayers Data Summary:\")\n",
    "print(df_players.describe())\n",
    "\n",
    "print(\"\\nMatches Data Summary:\")\n",
    "print(df_matches.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicate entries\n",
    "\n",
    "print(\"\\nDuplicate Rows in Bowling Data:\", df_bowling.duplicated().sum())\n",
    "print(\"Duplicate Rows in Batting Data:\", df_batting.duplicated().sum())\n",
    "print(\"Duplicate Rows in Players Data:\", df_players.duplicated().sum())\n",
    "print(\"Duplicate Rows in Matches Data:\", df_matches.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "\n",
    "# 1. Handle Bowling Data\n",
    "\n",
    "# Fill missing values in dots, fours, sixes with 0 if the bowler played\n",
    "df_bowling.fillna({\"dots\": 0, \"fours\": 0, \"sixes\": 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Handle Batting Data\n",
    "\n",
    "# Fill missing values in runs, balls, fours , sixes, strikeRate with 0 if the batter played\n",
    "df_batting.fillna({\"runs\": 0, \"balls\": 0, \"fours\": 0, \"sixes\": 0, \"strikeRate\": 0}, inplace=True)\n",
    "\n",
    "# Drop fielders if too many missing values\n",
    "if df_batting[\"fielders\"].isna().mean() > 0.4:\n",
    "    df_batting.drop(columns=[\"fielders\"], inplace=True)\n",
    "\n",
    "# Drop bowler if too many missing values\n",
    "if df_batting[\"bowler\"].isna().mean() > 0.4:\n",
    "    df_batting.drop(columns=[\"bowler\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Handle Players Data\n",
    "\n",
    "df_players.fillna({\"dob\": \"Unknown\", \"dod\": \"Unknown\", \"batting_style\": \"Unknown\", \"bowling_style\": \"Unknown\"}, inplace=True) # Fill missing values with \"Unknown\"\n",
    "\n",
    "# Drop image_url if too many missing values\n",
    "if df_players[\"image_url\"].isna().mean() > 0.4:\n",
    "    df_players.drop(columns=[\"image_url\"], inplace=True)\n",
    "\n",
    "# Drop image_metadata if too many missing values\n",
    "if df_players[\"image_metadata\"].isna().mean() > 0.4:\n",
    "    df_players.drop(columns=[\"image_metadata\"], inplace=True)    \n",
    "\n",
    "# Drop Players with missing DOB or country\n",
    "\n",
    "df_players.dropna(subset=[\"dob\", \"country_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Handle Matches Data\n",
    "\n",
    "# Fill missing innings data with \"Not Played\"\n",
    "innings_columns = [\"Innings1 Team2 Runs Scored\", \"Innings1 Team2 Wickets Fell\", \"Innings1 Team2 Extras Rec\", \"Innings2 Team1 Runs Scored\", \"Innings2 Team1 Wickets Fell\", \"Innings2 Team1 Extras Rec\", \n",
    "                   \"Innings2 Team2 Runs Scored\", \"Innings2 Team2 Wickets Fell\", \"Innings2 Team2 Extras Rec\"]\n",
    "for col in innings_columns:\n",
    "    df_matches[col] = df_matches[col].fillna(\"Not Played\")\n",
    "\n",
    "df_matches.fillna({\"Match Winner\": \"No Result\", \"MOM Player\": \"None\", \"Umpire 1\": \"Unknown\", \"Umpire 2\": \"Unknown\"}, inplace=True)\n",
    "\n",
    "# Drop referee if too many missing values\n",
    "if df_matches[\"Match Referee\"].isna().mean() > 0.4:\n",
    "    df_matches.drop(columns=[\"Match Referee\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bowling Stats Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating Player Bowling Stats\n",
    "\n",
    "agg_df = df_bowling[['Match ID', 'bowler id', 'team', 'opposition', 'innings', 'wickets', 'overs', 'balls', 'economy', 'conceded']]\n",
    "\n",
    "# Define aggregation rules\n",
    "agg_rules = {\n",
    "    'wickets': 'sum',      # Total wickets taken\n",
    "    'overs': 'sum',        # Total overs bowled\n",
    "    'balls': 'sum',        # Total balls delivered\n",
    "    'economy': 'mean',     # Average economy rate\n",
    "    'conceded': 'sum'      # Total runs conceded\n",
    "}\n",
    "\n",
    "# Group by 'Match ID' and 'bowler id', aggregate numeric stats, and keep first occurrence of categorical columns\n",
    "filtered_df_bowling = agg_df.groupby(['Match ID', 'bowler id']).agg({**agg_rules, 'team': 'first', 'opposition': 'first'}).reset_index()\n",
    "\n",
    "# Ensure unique rows\n",
    "filtered_df_bowling = filtered_df_bowling.drop_duplicates()\n",
    "\n",
    "# Merge df_bowling with df_players to get bowler names\n",
    "filtered_df_bowling = filtered_df_bowling.merge(df_players, left_on=\"bowler id\", right_on=\"player_id\", how=\"left\")\n",
    "\n",
    "# Drop unnecessary columns to keep it clean\n",
    "filtered_df_bowling.drop(columns=[\"bowler id\", \"player_id\", \"player_object_id\", \"dob\", \"dod\", \"gender\", \"batting_style\", \"bowling_style\", \"country_id\"], inplace=True)\n",
    "\n",
    "# Define the desired column order\n",
    "filtered_df_bowling = filtered_df_bowling[['Match ID', 'player_name', 'team', 'opposition', 'wickets', 'overs', 'balls', 'economy', 'conceded']]\n",
    "\n",
    "# Bowling DataFrame\n",
    "filtered_df_bowling.sort_values(by=['Match ID', 'player_name'], ascending=[False, True]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches DataFrame\n",
    "\n",
    "filtered_df_matches = df_matches[['Match ID', 'Match Start Date', 'Team1 Name', 'Team2 Name', 'Match Venue (Stadium)', 'Match Winner']]\n",
    "\n",
    "# Convert 'Match Start Date' to datetime for sorting\n",
    "\n",
    "filtered_df_matches.loc[:, \"Match Start Date\"] = pd.to_datetime(filtered_df_matches[\"Match Start Date\"])\n",
    "\n",
    "# Sort matches by date\n",
    "filtered_df_matches = filtered_df_matches.sort_values(by=\"Match Start Date\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data from matches dataframe into bowling dataframe\n",
    "\n",
    "filtered_df_bowling = filtered_df_bowling.merge(filtered_df_matches[[\"Match ID\", \"Match Start Date\", \"Match Venue (Stadium)\"]], on=\"Match ID\", how=\"left\")\n",
    "filtered_df_bowling = filtered_df_bowling.sort_values([\"player_name\", \"Match Start Date\"])\n",
    "\n",
    "# Calculate additional bowling metrics\n",
    "filtered_df_bowling[\"bowling_average\"] = (filtered_df_bowling[\"conceded\"] / filtered_df_bowling[\"wickets\"]).round(2)\n",
    "filtered_df_bowling.loc[filtered_df_bowling[\"wickets\"] == 0, \"bowling_average\"] = filtered_df_bowling[\"conceded\"].round(2)\n",
    "\n",
    "filtered_df_bowling[\"strike_rate\"] = (filtered_df_bowling[\"balls\"] / filtered_df_bowling[\"wickets\"]).round(2)\n",
    "filtered_df_bowling.loc[filtered_df_bowling[\"wickets\"] == 0, \"strike_rate\"] = filtered_df_bowling[\"balls\"].round(2)\n",
    "\n",
    "# Display updated dataset\n",
    "filtered_df_bowling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the bowler name\n",
    "bowler_name = \"Pat Cummins\"\n",
    "\n",
    "# Filter data for the selected player\n",
    "bowler_df = filtered_df_bowling[filtered_df_bowling[\"player_name\"] == bowler_name]\n",
    "\n",
    "bowler_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "metrics = [\"wickets\", \"economy\", \"bowling_average\", \"strike_rate\"]\n",
    "titles = [\"Wickets Taken\", \"Economy Rate\", \"Bowling Average\", \"Strike Rate\"]\n",
    "opposition_colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\"]  # Blue, Orange, Green, Red\n",
    "venue_colors = [\"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\"]  # Purple, Brown, Pink, Grey\n",
    "\n",
    "# Performance against Opponents\n",
    "fig_opposition = make_subplots(\n",
    "    rows=2, cols=2, subplot_titles=titles, vertical_spacing=0.15, horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    row, col = (i // 2) + 1, (i % 2) + 1  # Arrange in 2x2 grid\n",
    "    \n",
    "    # Group by opposition and sort by metric in descending order\n",
    "    if metric == \"wickets\":\n",
    "        data = bowler_df.groupby(\"opposition\", as_index=False)[metric].sum().sort_values(by=metric, ascending=False)\n",
    "    else:\n",
    "        data = bowler_df.groupby(\"opposition\", as_index=False)[metric].mean().sort_values(by=metric)\n",
    "    \n",
    "    trace = go.Bar(x=data[\"opposition\"], y=data[metric], marker=dict(color=opposition_colors[i]), name=titles[i])\n",
    "    \n",
    "    fig_opposition.add_trace(trace, row=row, col=col)\n",
    "\n",
    "fig_opposition.update_layout(\n",
    "    title_text=f\"{bowler_name} - Performance Against Opponents\", \n",
    "    height=900, width=1100,\n",
    "    showlegend=False\n",
    ")\n",
    "fig_opposition.show()\n",
    "\n",
    "# Performance at Venues\n",
    "\n",
    "venue_data = bowler_df.groupby(\"Match Venue (Stadium)\", as_index=False)[metrics].agg(\n",
    "    lambda x: x.sum() if \"wickets\" in x.name else x.mean()\n",
    ")\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    sorted_data = venue_data.sort_values(\n",
    "        by=metric, ascending=(metric == \"wickets\")\n",
    "    )\n",
    "    \n",
    "    # For non-wicket metrices, invert the color values to match reversed scale\n",
    "    if metric != \"wickets\":\n",
    "        color_data = sorted_data[metric].max() - sorted_data[metric]  # Invert the values\n",
    "    else:\n",
    "        color_data = sorted_data[metric]  # Keep original values\n",
    "    \n",
    "    fig_venue = px.bar(\n",
    "        sorted_data, x=metric, y=\"Match Venue (Stadium)\", color=color_data,\n",
    "        orientation=\"h\", title=f\"{bowler_name} - {titles[i]} at All Venues\",\n",
    "        labels={metric: titles[i], \"Match Venue (Stadium)\": \"Venue\"}, height=1200,\n",
    "        color_continuous_scale=px.colors.sequential.Plasma\n",
    "    )\n",
    "    \n",
    "    # Calculate min and max values from original data\n",
    "    min_val = sorted_data[metric].min()\n",
    "    max_val = sorted_data[metric].max()\n",
    "    \n",
    "    # Generate a range of tick values\n",
    "    tick_vals = np.linspace(min_val, max_val, 5)  # 5 ticks from min to max\n",
    "    \n",
    "    # Conditionally reverse the colorbar labels\n",
    "    if metric != \"wickets\":\n",
    "        tick_text = [str(round(val, 2)) for val in tick_vals[::-1]]  # Reverse labels\n",
    "        fig_venue.update_layout(\n",
    "            coloraxis=dict(\n",
    "                cmin=color_data.min(),  # Match inverted range\n",
    "                cmax=color_data.max(),\n",
    "                reversescale=False,  # Default gradient with inverted data\n",
    "                colorbar=dict(\n",
    "                    title=titles[i],  # Set colorbar label to metric title\n",
    "                    tickmode=\"array\",\n",
    "                    tickvals=np.linspace(color_data.min(), color_data.max(), 5),  # Full range of color data\n",
    "                    ticktext=tick_text,\n",
    "                    len=1.0,  # Full length of colorbar\n",
    "                    yanchor=\"middle\",\n",
    "                    y=0.5,\n",
    "                    ticklabelposition=\"outside\"  # Ensure labels are fully visible\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        tick_text = [str(round(val, 2)) for val in tick_vals]\n",
    "        fig_venue.update_layout(\n",
    "            coloraxis=dict(\n",
    "                cmin=min_val,\n",
    "                cmax=max_val,\n",
    "                reversescale=False,\n",
    "                colorbar=dict(\n",
    "                    title=titles[i],\n",
    "                    tickmode=\"array\",\n",
    "                    tickvals=np.linspace(min_val, max_val, 5),  # Full range of original data\n",
    "                    ticktext=tick_text,\n",
    "                    len=1.0,\n",
    "                    yanchor=\"middle\",\n",
    "                    y=0.5,  # Position at middle\n",
    "                    ticklabelposition=\"outside\"  # Ensure labels are fully visible\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    fig_venue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the date as index\n",
    "bowler_df.set_index(\"Match Start Date\", inplace=True)\n",
    "\n",
    "time_series_bowler_data = bowler_df[['wickets', 'economy', 'bowling_average', 'strike_rate']]\n",
    "\n",
    "# Split data\n",
    "train_size = int(len(time_series_bowler_data) * 0.8)\n",
    "train_data = time_series_bowler_data[:train_size]\n",
    "test_data = time_series_bowler_data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Augmented Dickey-Fuller (ADF) test to check for stationarity\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adf_test(series, metric_name):\n",
    "    series_clean = pd.Series(series).dropna()\n",
    "\n",
    "    result = adfuller(series_clean)\n",
    "\n",
    "    print(f'ADF Statistic for {metric_name}: {result[0]:.4f}')\n",
    "    print(f'p-value: {result[1]:.4f}')\n",
    "    \n",
    "    is_stationary = result[1] <= 0.05\n",
    "    if is_stationary:\n",
    "        print(f\"{metric_name} is likely stationary (p-value <= 0.05).\")\n",
    "    else:\n",
    "        print(f\"{metric_name} is likely non-stationary (p-value > 0.05). Consider differencing.\")\n",
    "    \n",
    "    return result[1], is_stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ADF test on all columns in training data\n",
    "for column in train_data.columns:\n",
    "    print(f\"\\nTesting stationarity for '{column}'...\")\n",
    "    p_value, is_stationary = adf_test(train_data[column], metric_name=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ACF and PACF to identify autocorrelation and partial autocorrelation patterns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def plot_acf_pacf(train_data, lags=20):\n",
    "    for column in train_data.columns:\n",
    "        series = train_data[column].dropna()\n",
    "        allowed_lags = min(lags, max(1, (len(series) // 2) - 1)) # If the number of observations is small, the lag is automatically reduced to fit statsmodels' requirements\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # ACF Plot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sm.graphics.tsa.plot_acf(series, lags=allowed_lags, ax=plt.gca())\n",
    "        plt.title(f'ACF of {column} (lags={allowed_lags})')\n",
    "\n",
    "        # PACF Plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sm.graphics.tsa.plot_pacf(series, lags=allowed_lags, ax=plt.gca())\n",
    "        plt.title(f'PACF of {column} (lags={allowed_lags})')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ACF and PACF for all columns in training data\n",
    "plot_acf_pacf(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit manually specified ARIMA models and compare with naive forecasts\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Manually specified ARIMA (p, d, q) values for each metric\n",
    "manual_orders = {\n",
    "    'wickets': (1, 0, 2),\n",
    "    'economy': (1, 0, 2),\n",
    "    'bowling_average': (1, 0, 2),\n",
    "    'strike_rate': (1, 0, 0)\n",
    "}\n",
    "\n",
    "arima_models = {}\n",
    "forecasts = {}\n",
    "naive_forecasts = {}\n",
    "metrics = {}\n",
    "\n",
    "# Number of steps to forecast\n",
    "n_test = len(test_data)\n",
    "\n",
    "for column in time_series_bowler_data.columns:\n",
    "    print(f\"\\nProcessing {column} with ARIMA order {manual_orders[column]}...\")\n",
    "\n",
    "    # Fit ARIMA with manually specified order\n",
    "    arima_model = ARIMA(train_data[column].dropna(), order=manual_orders[column])\n",
    "    fitted_model = arima_model.fit()\n",
    "    arima_models[column] = fitted_model\n",
    "\n",
    "    # Forecast the test period with ARIMA\n",
    "    forecast = fitted_model.forecast(steps=n_test)\n",
    "    forecasts[column] = forecast\n",
    "\n",
    "    # Naive forecast: repeat the last training value\n",
    "    last_value = train_data[column].iloc[-1]\n",
    "    naive_forecast = np.full(n_test, last_value)\n",
    "    naive_forecasts[column] = naive_forecast\n",
    "\n",
    "    # Calculate error metrics for ARIMA\n",
    "    mse = mean_squared_error(test_data[column], forecast)\n",
    "    mae = mean_absolute_error(test_data[column], forecast)\n",
    "    metrics[column] = {'MSE': mse, 'MAE': mae}\n",
    "\n",
    "    # Calculate error metrics for Naive model\n",
    "    naive_mse = mean_squared_error(test_data[column], naive_forecast)\n",
    "    naive_mae = mean_absolute_error(test_data[column], naive_forecast)\n",
    "\n",
    "    print(f\"Error Metrics for {column} (ARIMA):\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"Error Metrics for {column} (Naive):\")\n",
    "    print(f\"MSE: {naive_mse:.4f}\")\n",
    "    print(f\"MAE: {naive_mae:.4f}\")\n",
    "\n",
    "    # Plot actual vs predicted vs naive for test period\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(train_data[column], label='Training Data', color='gray')\n",
    "    plt.plot(test_data[column], label='Actual Test Data', color='blue')\n",
    "    plt.plot(test_data.index, forecast, label='ARIMA Predicted', color='orange')\n",
    "    plt.plot(test_data.index, naive_forecast, label='Naive Predicted', color='green', linestyle='--')\n",
    "    plt.title(f'{column}: Actual vs ARIMA vs Naive Predicted')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Forecasting with ARIMA, SARIMA, and Naive Baselines\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pmdarima import auto_arima\n",
    "from itertools import product\n",
    "\n",
    "class TimeSeriesForecaster:\n",
    "    def __init__(self, train_data, test_data, seasonal_period=12):\n",
    "        # Initialize with train-test data\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.seasonal_period = seasonal_period\n",
    "\n",
    "        # Initialize storage\n",
    "        self.arima_models = {}\n",
    "        self.sarima_models = {}\n",
    "        self.best_models = {}\n",
    "        self.forecasts = {}\n",
    "        self.naive_forecasts = {}\n",
    "        self.metrics = {}\n",
    "\n",
    "        # Grid search parameters\n",
    "        self.p_values = range(0, 7)\n",
    "        self.d_values = [0]  # For stationary data\n",
    "        self.q_values = range(0, 7)\n",
    "\n",
    "        self.n_test = len(self.test_data)\n",
    "\n",
    "    def grid_search_arima(self, train_data, test_data):\n",
    "        best_score, best_order = float(\"inf\"), None\n",
    "        for p, d, q in product(self.p_values, self.d_values, self.q_values):\n",
    "            try:\n",
    "                model = ARIMA(train_data, order=(p, d, q))\n",
    "                fitted_model = model.fit()\n",
    "                forecast = fitted_model.forecast(steps=len(test_data))\n",
    "                mse = mean_squared_error(test_data, forecast)\n",
    "                if mse < best_score:\n",
    "                    best_score, best_order = mse, (p, d, q)\n",
    "                print(f\"ARIMA{p,d,q} MSE: {mse:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"ARIMA{p,d,q} failed with error: {e}\")\n",
    "                continue\n",
    "        if best_order is None:\n",
    "            print(\"Warning: No valid ARIMA model found with grid search. Falling back to auto_arima.\")\n",
    "        return best_order\n",
    "\n",
    "    def fit_arima(self, train_data, test_data):\n",
    "        best_arima_order = self.grid_search_arima(train_data, test_data)\n",
    "        if best_arima_order is None:\n",
    "            print(\"Using auto_arima as fallback for ARIMA...\")\n",
    "            auto_arima_model = auto_arima(\n",
    "                train_data, start_p=0, start_q=0, max_p=6, max_q=6, d=0,\n",
    "                seasonal=False, trace=True, error_action='ignore',\n",
    "                suppress_warnings=True, stepwise=True\n",
    "            )\n",
    "            best_arima_order = auto_arima_model.order\n",
    "            print(f\"Fallback ARIMA order from auto_arima: {best_arima_order}\")\n",
    "\n",
    "        arima_model = ARIMA(train_data, order=best_arima_order)\n",
    "        fitted_arima = arima_model.fit()\n",
    "        arima_forecast = fitted_arima.forecast(steps=len(test_data))\n",
    "        return fitted_arima, arima_forecast, best_arima_order\n",
    "\n",
    "    def fit_sarima(self, train_data, test_data):\n",
    "        auto_sarima = auto_arima(\n",
    "            train_data, start_p=0, start_q=0, max_p=6, max_q=6, d=0,\n",
    "            seasonal=True, m=self.seasonal_period, start_P=0, start_Q=0,\n",
    "            max_P=2, max_Q=2, D=0, trace=True, error_action='ignore',\n",
    "            suppress_warnings=True, stepwise=True\n",
    "        )\n",
    "\n",
    "        best_sarima_order = auto_sarima.order\n",
    "        best_sarima_seasonal_order = auto_sarima.seasonal_order\n",
    "        sarima_model = SARIMAX(\n",
    "            train_data, order=best_sarima_order,\n",
    "            seasonal_order=best_sarima_seasonal_order\n",
    "        )\n",
    "        fitted_sarima = sarima_model.fit(disp=False)\n",
    "        sarima_forecast = fitted_sarima.forecast(steps=len(test_data))\n",
    "        return fitted_sarima, sarima_forecast, best_sarima_order, best_sarima_seasonal_order\n",
    "\n",
    "    def fit_models(self):\n",
    "        for column in self.train_data.columns:\n",
    "            print(f\"\\nProcessing {column}...\")\n",
    "\n",
    "            # Fit ARIMA\n",
    "            print(\"Fitting ARIMA...\")\n",
    "            fitted_arima, arima_forecast, best_arima_order = self.fit_arima(\n",
    "                self.train_data[column].dropna(), self.test_data[column]\n",
    "            )\n",
    "            self.arima_models[column] = fitted_arima\n",
    "            print(f\"Best ARIMA order for {column}: {best_arima_order}\")\n",
    "\n",
    "            # Fit SARIMA\n",
    "            print(\"Fitting SARIMA...\")\n",
    "            fitted_sarima, sarima_forecast, best_sarima_order, best_sarima_seasonal_order = self.fit_sarima(\n",
    "                self.train_data[column].dropna(), self.test_data[column]\n",
    "            )\n",
    "            self.sarima_models[column] = fitted_sarima\n",
    "            print(f\"Best SARIMA order for {column}: {best_sarima_order}, Seasonal: {best_sarima_seasonal_order}\")\n",
    "\n",
    "            # Naive forecast\n",
    "            last_value = self.train_data[column].iloc[-1]\n",
    "            naive_forecast = np.full(self.n_test, last_value)\n",
    "            self.naive_forecasts[column] = naive_forecast\n",
    "\n",
    "            # Metrics\n",
    "            arima_mse = mean_squared_error(self.test_data[column], arima_forecast)\n",
    "            arima_mae = mean_absolute_error(self.test_data[column], arima_forecast)\n",
    "            sarima_mse = mean_squared_error(self.test_data[column], sarima_forecast)\n",
    "            sarima_mae = mean_absolute_error(self.test_data[column], sarima_forecast)\n",
    "            naive_mse = mean_squared_error(self.test_data[column], naive_forecast)\n",
    "            naive_mae = mean_absolute_error(self.test_data[column], naive_forecast)\n",
    "\n",
    "            # Best model selection\n",
    "            if arima_mse < sarima_mse and arima_mse < naive_mse:\n",
    "                self.best_models[column] = {'model': 'ARIMA', 'fitted_model': fitted_arima, 'forecast': arima_forecast}\n",
    "                self.metrics[column] = {'MSE': arima_mse, 'MAE': arima_mae}\n",
    "                self.forecasts[column] = arima_forecast\n",
    "                print(f\"Selected ARIMA for {column} with MSE: {arima_mse:.4f}, MAE: {arima_mae:.4f}\")\n",
    "            elif sarima_mse < arima_mse and sarima_mse < naive_mse:\n",
    "                self.best_models[column] = {'model': 'SARIMA', 'fitted_model': fitted_sarima, 'forecast': sarima_forecast}\n",
    "                self.metrics[column] = {'MSE': sarima_mse, 'MAE': sarima_mae}\n",
    "                self.forecasts[column] = sarima_forecast\n",
    "                print(f\"Selected SARIMA for {column} with MSE: {sarima_mse:.4f}, MAE: {sarima_mae:.4f}\")\n",
    "            else:\n",
    "                self.best_models[column] = {'model': 'Naive', 'fitted_model': None, 'forecast': naive_forecast}\n",
    "                self.metrics[column] = {'MSE': naive_mse, 'MAE': naive_mae}\n",
    "                self.forecasts[column] = naive_forecast\n",
    "                print(f\"Selected Naive for {column} with MSE: {naive_mse:.4f}, MAE: {naive_mae:.4f}\")\n",
    "\n",
    "            # Metrics summary\n",
    "            print(f\"Error Metrics for {column} (ARIMA): MSE: {arima_mse:.4f}, MAE: {arima_mae:.4f}\")\n",
    "            print(f\"Error Metrics for {column} (SARIMA): MSE: {sarima_mse:.4f}, MAE: {sarima_mae:.4f}\")\n",
    "            print(f\"Error Metrics for {column} (Naive): MSE: {naive_mse:.4f}, MAE: {naive_mae:.4f}\")\n",
    "\n",
    "    def visualize(self):\n",
    "        for column in self.train_data.columns:\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.plot(self.train_data[column], label='Training Data', color='gray')\n",
    "            plt.plot(self.test_data[column], label='Actual Test Data', color='blue')\n",
    "            plt.plot(self.test_data.index, self.forecasts[column],\n",
    "                     label=f'{self.best_models[column][\"model\"]} Predicted', color='orange')\n",
    "            plt.plot(self.test_data.index, self.naive_forecasts[column],\n",
    "                     label='Naive Predicted', color='green', linestyle='--')\n",
    "            plt.title(f'{column}: Actual vs {self.best_models[column][\"model\"]} vs Naive Predicted')\n",
    "            plt.xlabel('Year')\n",
    "            plt.ylabel(column)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            print(f\"Last training value for {column}: {self.train_data[column].iloc[-1]}, \"\n",
    "                  f\"Mean test value: {self.test_data[column].mean()}, \"\n",
    "                  f\"Std test value: {self.test_data[column].std()}\")\n",
    "\n",
    "    def forecast_future(self, steps=5):\n",
    "        future_forecasts = {}\n",
    "        future_naive_forecasts = {}\n",
    "\n",
    "        for column in self.train_data.columns:\n",
    "            if self.best_models[column]['model'] in ['ARIMA', 'SARIMA']:\n",
    "                future_forecast = self.best_models[column]['fitted_model'].forecast(steps=steps)\n",
    "            else:\n",
    "                future_forecast = np.full(steps, self.train_data[column].iloc[-1])\n",
    "            future_forecasts[column] = future_forecast\n",
    "\n",
    "            last_value = self.train_data[column].iloc[-1]\n",
    "            future_naive = np.full(steps, last_value)\n",
    "            future_naive_forecasts[column] = future_naive\n",
    "\n",
    "            print(f\"\\nFuture Forecast for {column} (next {steps} steps):\")\n",
    "            print(f\"{self.best_models[column]['model']} Forecast:\")\n",
    "            print(future_forecast)\n",
    "            print(\"Naive Forecast:\")\n",
    "            print(future_naive)\n",
    "\n",
    "        return future_forecasts, future_naive_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Forecasting\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For bowling data\n",
    "    bowling_forecaster = TimeSeriesForecaster(train_data, test_data)\n",
    "    bowling_forecaster.fit_models()\n",
    "    bowling_forecaster.visualize()\n",
    "    bowling_future, bowling_naive_future = bowling_forecaster.forecast_future(steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batting Stats Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating Player Batting Stats\n",
    "\n",
    "# Batting Average\n",
    "df_batting[\"batting_average\"] = (df_batting[\"runs\"] / df_batting[\"isOut\"]).round(2)\n",
    "df_batting.loc[df_batting[\"isOut\"] == 0, \"batting_average\"] = df_batting[\"runs\"].round(2)\n",
    "\n",
    "agg_df_batting = df_batting[['Match ID', 'batsman', 'team', 'innings', 'runs', 'balls', 'fours', 'sixes', 'batting_average', 'strikeRate']]\n",
    "\n",
    "agg_rules_batting = {\n",
    "    'runs': 'sum',              # Total runs scored\n",
    "    'balls': 'sum',             # Total balls faced\n",
    "    'fours': 'sum',             # Total fours hit  \n",
    "    'sixes': 'sum',             # Total sixes hit \n",
    "    'batting_average': 'mean',  # Average of batting average\n",
    "    'strikeRate': 'mean'        # Average strike rate\n",
    "}\n",
    "\n",
    "# Group by 'Match ID' and 'batsman id', aggregate numeric stats, and keep first occurrence of categorical columns\n",
    "filtered_df_batting = agg_df_batting.groupby(['Match ID', 'batsman']).agg({**agg_rules_batting, 'team': 'first'}).reset_index()\n",
    "\n",
    "filtered_df_batting = filtered_df_batting.drop_duplicates()\n",
    "\n",
    "# Merge filtered_df_batting with df_players to get batter names\n",
    "filtered_df_batting = filtered_df_batting.merge(df_players, left_on=\"batsman\", right_on=\"player_id\", how=\"left\")\n",
    "\n",
    "filtered_df_batting.drop(columns=[\"batsman\", \"player_id\", \"player_object_id\", \"dob\", \"dod\", \"gender\", \"batting_style\", \"bowling_style\", \"country_id\"], inplace=True)\n",
    "\n",
    "# Merge df_batting with df_matches to get Team1 Name and Team2 Name\n",
    "filtered_df_batting = filtered_df_batting.merge(df_matches[[\"Match ID\", \"Team1 Name\", \"Team2 Name\"]], on=\"Match ID\", how=\"left\")\n",
    "\n",
    "# Determine Opponent Team\n",
    "filtered_df_batting[\"opposition\"] = filtered_df_batting.apply(\n",
    "    lambda row: row[\"Team2 Name\"] if row[\"team\"] == row[\"Team1 Name\"] else row[\"Team1 Name\"], axis=1\n",
    ")\n",
    "\n",
    "filtered_df_batting.drop(columns=[\"Team1 Name\", \"Team2 Name\"], inplace=True)\n",
    "\n",
    "filtered_df_batting = filtered_df_batting.merge(filtered_df_matches[[\"Match ID\", \"Match Start Date\", \"Match Venue (Stadium)\"]], on=\"Match ID\", how=\"left\")\n",
    "\n",
    "filtered_df_batting = filtered_df_batting[['Match ID', 'player_name', 'team', 'opposition', 'runs', 'balls', 'fours', 'sixes', 'batting_average', 'strikeRate', 'Match Start Date', 'Match Venue (Stadium)']]\n",
    "\n",
    "filtered_df_batting = filtered_df_batting.sort_values([\"player_name\", \"Match Start Date\"])\n",
    "\n",
    "# Batting DataFrame\n",
    "filtered_df_batting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the player name\n",
    "batter_name = \"Travis Head\"\n",
    "\n",
    "# Filter data for the selected player\n",
    "batter_df = filtered_df_batting[filtered_df_batting[\"player_name\"] == batter_name]\n",
    "\n",
    "batter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "# Define metrics and titles for batting performance\n",
    "metrics = [\"runs\", \"batting_average\", \"strikeRate\"]\n",
    "titles = [\"Runs Scored\", \"Batting Average\", \"Strike Rate\"]\n",
    "opposition_colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"]  # Blue, Orange, Green\n",
    "\n",
    "# Performance against Opponents\n",
    "fig_opposition = make_subplots(\n",
    "    rows=1, cols=3, subplot_titles=titles, horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    # Arrange in 1x3 grid\n",
    "    col = i + 1\n",
    "    \n",
    "    # Group by opposition and sort by metric in descending order\n",
    "    if metric == \"runs\":\n",
    "        data = batter_df.groupby(\"opposition\", as_index=False)[metric].sum().sort_values(by=metric, ascending=False)\n",
    "    else:\n",
    "        data = batter_df.groupby(\"opposition\", as_index=False)[metric].mean().sort_values(by=metric, ascending=False)\n",
    "    \n",
    "    trace = go.Bar(\n",
    "        x=data[\"opposition\"], \n",
    "        y=data[metric], \n",
    "        marker=dict(color=opposition_colors[i]), \n",
    "        name=titles[i]\n",
    "    )\n",
    "    \n",
    "    fig_opposition.add_trace(trace, row=1, col=col)\n",
    "\n",
    "# Update layout\n",
    "fig_opposition.update_layout(\n",
    "    title_text=f\"{batter_name} - Performance Against Opponents\", \n",
    "    height=700, \n",
    "    width=1750,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Display the figure\n",
    "fig_opposition.show()\n",
    "\n",
    "# Performance by Match Venue\n",
    "venue_data = batter_df.groupby(\"Match Venue (Stadium)\", as_index=False)[metrics].agg(\n",
    "    lambda x: x.sum() if \"runs\" in x.name else x.mean()\n",
    ")\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    sorted_data = venue_data.sort_values(\n",
    "        by=metric, ascending=False  # Sort data in descending order\n",
    "    )\n",
    "    \n",
    "    color_data = sorted_data[metric]  # Keep original values for all\n",
    "    \n",
    "    fig_venue = px.bar(\n",
    "        sorted_data, \n",
    "        x=metric, \n",
    "        y=\"Match Venue (Stadium)\", \n",
    "        color=color_data,\n",
    "        orientation=\"h\", \n",
    "        title=f\"{batter_name} - {titles[i]} by Match Venue\",\n",
    "        labels={metric: titles[i], \"Match Venue (Stadium)\": \"Venue\"},\n",
    "        height=1200,\n",
    "        width=1750,\n",
    "        color_continuous_scale=px.colors.sequential.Plasma\n",
    "    )\n",
    "    \n",
    "    # Generate a range of tick values directly from color_data\n",
    "    tick_vals = np.linspace(color_data.min(), color_data.max(), 5)  # 5 ticks from min to max\n",
    "    \n",
    "    # Use the same configuration for all metrics\n",
    "    tick_text = [str(round(val, 2)) for val in tick_vals]\n",
    "    fig_venue.update_layout(\n",
    "        coloraxis=dict(\n",
    "            cmin=color_data.min(),\n",
    "            cmax=color_data.max(),\n",
    "            reversescale=False,  # Keep color scale aligned with values\n",
    "            colorbar=dict(\n",
    "                title=titles[i],\n",
    "                tickmode=\"array\",\n",
    "                tickvals=tick_vals,\n",
    "                ticktext=tick_text,\n",
    "                len=1.0,\n",
    "                yanchor=\"middle\",\n",
    "                y=0.5,\n",
    "                ticklabelposition=\"outside\"\n",
    "            )\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            autorange=\"reversed\"  # Highest values at top\n",
    "        ),\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig_venue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batter_df.set_index(\"Match Start Date\", inplace=True)  \n",
    "# batter_df.index = pd.to_datetime(batter_df.index)   \n",
    "\n",
    "time_series_batter_data = batter_df[['runs', 'batting_average', 'strikeRate']]\n",
    "\n",
    "# Split data\n",
    "train_size = int(len(time_series_batter_data) * 0.8)\n",
    "train_data = time_series_batter_data[:train_size]\n",
    "test_data = time_series_batter_data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ADF test on all columns in training data\n",
    "for column in train_data.columns:\n",
    "    print(f\"\\nTesting stationarity for '{column}'...\")\n",
    "    p_value, is_stationary = adf_test(train_data[column], metric_name=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ACF and PACF for all columns in training data\n",
    "plot_acf_pacf(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit manually specified ARIMA models and compare with naive forecasts\n",
    "\n",
    "manual_orders = {\n",
    "    'runs': (2, 0, 3),\n",
    "    'batting_average': (2, 0, 3),\n",
    "    'strikeRate': (2, 0, 4)\n",
    "}\n",
    "\n",
    "arima_models = {}\n",
    "forecasts = {}\n",
    "naive_forecasts = {}\n",
    "metrics = {}\n",
    "\n",
    "n_test = len(test_data)\n",
    "\n",
    "for column in time_series_batter_data.columns:\n",
    "    print(f\"\\nProcessing {column} with ARIMA order {manual_orders[column]}...\")\n",
    "\n",
    "    # Fit ARIMA with manually specified order\n",
    "    arima_model = ARIMA(train_data[column].dropna(), order=manual_orders[column])\n",
    "    fitted_model = arima_model.fit()\n",
    "    arima_models[column] = fitted_model\n",
    "\n",
    "    # Forecast the test period with ARIMA\n",
    "    forecast = fitted_model.forecast(steps=n_test)\n",
    "    forecasts[column] = forecast\n",
    "\n",
    "    # Naive forecast\n",
    "    last_value = train_data[column].iloc[-1]\n",
    "    naive_forecast = np.full(n_test, last_value)\n",
    "    naive_forecasts[column] = naive_forecast\n",
    "\n",
    "    # Calculate error metrics for ARIMA\n",
    "    mse = mean_squared_error(test_data[column], forecast)\n",
    "    mae = mean_absolute_error(test_data[column], forecast)\n",
    "    metrics[column] = {'MSE': mse, 'MAE': mae}\n",
    "\n",
    "    # Calculate error metrics for Naive model\n",
    "    naive_mse = mean_squared_error(test_data[column], naive_forecast)\n",
    "    naive_mae = mean_absolute_error(test_data[column], naive_forecast)\n",
    "\n",
    "    print(f\"Error Metrics for {column} (ARIMA):\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"Error Metrics for {column} (Naive):\")\n",
    "    print(f\"MSE: {naive_mse:.4f}\")\n",
    "    print(f\"MAE: {naive_mae:.4f}\")\n",
    "\n",
    "    # Plot actual vs predicted vs naive for test period\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(train_data[column], label='Training Data', color='gray')\n",
    "    plt.plot(test_data[column], label='Actual Test Data', color='blue')\n",
    "    plt.plot(test_data.index, forecast, label='ARIMA Predicted', color='orange')\n",
    "    plt.plot(test_data.index, naive_forecast, label='Naive Predicted', color='green', linestyle='--')\n",
    "    plt.title(f'{column}: Actual vs ARIMA vs Naive Predicted')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Forecasting\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For batting data\n",
    "    batting_forecaster = TimeSeriesForecaster(train_data, test_data)\n",
    "    batting_forecaster.fit_models()\n",
    "    batting_forecaster.visualize()\n",
    "    batting_future, batting_naive_future = batting_forecaster.forecast_future(steps=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
