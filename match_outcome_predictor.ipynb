{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "df_matches = pd.read_csv(\"test_Matches_Data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Basic Info\n",
    "\n",
    "df_matches.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 10 Random Rows\n",
    "\n",
    "df_matches.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "\n",
    "print(\"\\nMissing Values in Matches Data:\")\n",
    "print(df_matches.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics\n",
    "\n",
    "print(\"\\nMatches Data Summary:\")\n",
    "print(df_matches.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicate entries\n",
    "\n",
    "print(\"Duplicate Rows in Matches Data:\", df_matches.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "\n",
    "# Fill missing innings data with \"Not Played\"\n",
    "innings_columns = [\"Innings1 Team2 Runs Scored\", \"Innings1 Team2 Wickets Fell\", \"Innings1 Team2 Extras Rec\", \"Innings2 Team1 Runs Scored\", \"Innings2 Team1 Wickets Fell\", \"Innings2 Team1 Extras Rec\", \n",
    "                   \"Innings2 Team2 Runs Scored\", \"Innings2 Team2 Wickets Fell\", \"Innings2 Team2 Extras Rec\"]\n",
    "for col in innings_columns:\n",
    "    df_matches[col] = df_matches[col].fillna(\"Not Played\")\n",
    "\n",
    "df_matches.fillna({\"Match Winner\": \"No Result\", \"MOM Player\": \"None\", \"Umpire 1\": \"Unknown\", \"Umpire 2\": \"Unknown\"}, inplace=True)\n",
    "\n",
    "# Drop referee if too many missing values\n",
    "if df_matches[\"Match Referee\"].isna().mean() > 0.4:\n",
    "    df_matches.drop(columns=[\"Match Referee\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches DataFrame\n",
    "\n",
    "filtered_df_matches = df_matches[['Match ID', 'Match Start Date', 'Team1 Name', 'Team2 Name', 'Match Venue (Stadium)', 'Match Winner']]\n",
    "\n",
    "# Convert 'Match Start Date' to datetime for sorting\n",
    "\n",
    "filtered_df_matches.loc[:, \"Match Start Date\"] = pd.to_datetime(filtered_df_matches[\"Match Start Date\"])\n",
    "\n",
    "# Sort matches by date\n",
    "filtered_df_matches = filtered_df_matches.sort_values(by=\"Match Start Date\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match Result Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize team order\n",
    "filtered_df_matches[\"Team_A\"], filtered_df_matches[\"Team_B\"] = zip(\n",
    "    *filtered_df_matches.apply(lambda row: sorted([row[\"Team1 Name\"], row[\"Team2 Name\"]]), axis=1)\n",
    ")\n",
    "\n",
    "# Aggregate match stats\n",
    "matchup_stats = (\n",
    "    filtered_df_matches.groupby([\"Team_A\", \"Team_B\"])\n",
    "    .agg(\n",
    "        Total_Matches=(\"Match ID\", \"count\"),\n",
    "        Team_A_Wins=(\"Match Winner\", lambda x: sum(x == filtered_df_matches.loc[x.index, \"Team_A\"])),\n",
    "        Team_B_Wins=(\"Match Winner\", lambda x: sum(x == filtered_df_matches.loc[x.index, \"Team_B\"])),\n",
    "        No_Result=(\"Match Winner\", lambda x: sum(x == \"No Result\"))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Compute Losses\n",
    "matchup_stats[\"Team_A_Losses\"] = matchup_stats[\"Team_B_Wins\"]\n",
    "matchup_stats[\"Team_B_Losses\"] = matchup_stats[\"Team_A_Wins\"]\n",
    "\n",
    "# Compute Percentages\n",
    "matchup_stats[\"Team_A Win %\"] = (matchup_stats[\"Team_A_Wins\"] / matchup_stats[\"Total_Matches\"]) * 100\n",
    "matchup_stats[\"Team_B Win %\"] = (matchup_stats[\"Team_B_Wins\"] / matchup_stats[\"Total_Matches\"]) * 100\n",
    "matchup_stats[\"No Result %\"] = (matchup_stats[\"No_Result\"] / matchup_stats[\"Total_Matches\"]) * 100\n",
    "matchup_stats[\"Team_A Loss %\"] = (matchup_stats[\"Team_A_Losses\"] / matchup_stats[\"Total_Matches\"]) * 100\n",
    "matchup_stats[\"Team_B Loss %\"] = (matchup_stats[\"Team_B_Losses\"] / matchup_stats[\"Total_Matches\"]) * 100\n",
    "\n",
    "# Rename columns for clarity\n",
    "matchup_stats.rename(columns={\n",
    "    \"Team_A\": \"Team1\", \"Team_B\": \"Team2\",\n",
    "    \"Team_A_Wins\": \"Team1 Wins\", \"Team_B_Wins\": \"Team2 Wins\",\n",
    "    \"Team_A_Losses\": \"Team1 Losses\", \"Team_B_Losses\": \"Team2 Losses\",\n",
    "    \"Team_A Win %\": \"Team1 Win %\", \"Team_B Win %\": \"Team2 Win %\",\n",
    "    \"Team_A Loss %\": \"Team1 Loss %\", \"Team_B Loss %\": \"Team2 Loss %\",\n",
    "    \"No_Result\": \"No Result Matches\", \"No Result %\": \"No Result %\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Matchup DataFrame\n",
    "matchup_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute stats for Team1\n",
    "venue_stats = (\n",
    "    filtered_df_matches.groupby([\"Team1 Name\", \"Match Venue (Stadium)\"])\n",
    "    .agg(\n",
    "        Total_Matches=(\"Match ID\", \"count\"),\n",
    "        Wins=(\"Match Winner\", lambda x: sum(x == filtered_df_matches.loc[x.index, \"Team1 Name\"])),\n",
    "        No_Result=(\"Match Winner\", lambda x: sum(x == \"No Result\"))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Compute stats for Team2\n",
    "venue_stats_team2 = (\n",
    "    filtered_df_matches.groupby([\"Team2 Name\", \"Match Venue (Stadium)\"])\n",
    "    .agg(\n",
    "        Total_Matches=(\"Match ID\", \"count\"),\n",
    "        Wins=(\"Match Winner\", lambda x: sum(x == filtered_df_matches.loc[x.index, \"Team2 Name\"])),\n",
    "        No_Result=(\"Match Winner\", lambda x: sum(x == \"No Result\"))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Standardize column names\n",
    "venue_stats.rename(columns={\"Team1 Name\": \"Team\"}, inplace=True)\n",
    "venue_stats_team2.rename(columns={\"Team2 Name\": \"Team\"}, inplace=True)\n",
    "\n",
    "# Merge both datasets to consolidate stats\n",
    "final_venue_stats = pd.concat([venue_stats, venue_stats_team2])\n",
    "\n",
    "# Group by Team + Venue to sum up all stats\n",
    "final_venue_stats = (\n",
    "    final_venue_stats.groupby([\"Team\", \"Match Venue (Stadium)\"])\n",
    "    .agg(\n",
    "        Total_Matches=(\"Total_Matches\", \"sum\"),\n",
    "        Wins=(\"Wins\", \"sum\"),\n",
    "        No_Result=(\"No_Result\", \"sum\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Compute Losses\n",
    "final_venue_stats[\"Losses\"] = (\n",
    "    final_venue_stats[\"Total_Matches\"] - final_venue_stats[\"Wins\"] - final_venue_stats[\"No_Result\"]\n",
    ")\n",
    "\n",
    "# Compute Win %, Loss %, and No Result %\n",
    "final_venue_stats[\"Win %\"] = (final_venue_stats[\"Wins\"] / final_venue_stats[\"Total_Matches\"]) * 100\n",
    "final_venue_stats[\"No Result %\"] = (final_venue_stats[\"No_Result\"] / final_venue_stats[\"Total_Matches\"]) * 100\n",
    "final_venue_stats[\"Loss %\"] = (final_venue_stats[\"Losses\"] / final_venue_stats[\"Total_Matches\"]) * 100\n",
    "\n",
    "# Venue DataFrame\n",
    "final_venue_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_team_performance(team_name, matchup_stats):\n",
    "    # Filter data for the selected team\n",
    "    team_data = matchup_stats[(matchup_stats[\"Team1\"] == team_name) | (matchup_stats[\"Team2\"] == team_name)].copy()\n",
    "\n",
    "    # Determine opponent column dynamically\n",
    "    team_data[\"Opponent\"] = team_data.apply(lambda row: row[\"Team2\"] if row[\"Team1\"] == team_name else row[\"Team1\"], axis=1)\n",
    "\n",
    "    # Adjust win/loss columns based on the selected team\n",
    "    team_data[\"Team Wins\"] = team_data.apply(lambda row: row[\"Team1 Wins\"] if row[\"Team1\"] == team_name else row[\"Team2 Wins\"], axis=1)\n",
    "    team_data[\"Opponent Wins\"] = team_data.apply(lambda row: row[\"Team2 Wins\"] if row[\"Team1\"] == team_name else row[\"Team1 Wins\"], axis=1)\n",
    "    team_data[\"Team Win %\"] = team_data.apply(lambda row: row[\"Team1 Win %\"] if row[\"Team1\"] == team_name else row[\"Team2 Win %\"], axis=1)\n",
    "    team_data[\"Opponent Win %\"] = team_data.apply(lambda row: row[\"Team2 Win %\"] if row[\"Team1\"] == team_name else row[\"Team1 Win %\"], axis=1)\n",
    "\n",
    "    team_data = team_data.sort_values(by=['Team Win %', 'No Result %', 'Opponent Win %', 'Team Wins'], ascending=[False, False, True, False])\n",
    "\n",
    "    # Create the bar chart\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=team_data[\"Opponent\"], \n",
    "        y=team_data[\"Total_Matches\"], \n",
    "        name=\"Total Matches\",\n",
    "        marker_color=\"DodgerBlue\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=team_data[\"Opponent\"], \n",
    "        y=team_data[\"Team Wins\"], \n",
    "        name=f\"{team_name} Wins\",\n",
    "        marker_color=\"green\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=team_data[\"Opponent\"], \n",
    "        y=team_data[\"Opponent Wins\"], \n",
    "        name=\"Opponent Wins\",\n",
    "        marker_color=\"red\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=team_data[\"Opponent\"], \n",
    "        y=team_data[\"No Result Matches\"], \n",
    "        name=\"No Result Matches\",\n",
    "        marker_color=\"orange\"\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"{team_name} Performance Against Opponents\",\n",
    "        xaxis_title=\"Opponent\",\n",
    "        yaxis_title=\"Matches\",\n",
    "        barmode=\"group\",\n",
    "        legend_title=\"Match Outcome\"\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Plot Matchup Stats\n",
    "plot_team_performance(\"South Africa\", matchup_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_top_venues_by_win_percentage(team_name, final_venue_stats):\n",
    "    venue_data = final_venue_stats[(final_venue_stats[\"Team\"] == team_name) & (final_venue_stats[\"Total_Matches\"] >=5) ].copy() # Minimum 5 matches on that venue\n",
    "\n",
    "    # Sort venues by Win % in descending order and take top 10\n",
    "    top_venues = venue_data.sort_values(by=[\"Win %\", \"No Result %\", \"Loss %\", \"Wins\"], ascending=[False, False, True, False]).head(20)\n",
    "\n",
    "    # Create a horizontal bar chart\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add separate bars for each metric\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=top_venues[\"Match Venue (Stadium)\"], \n",
    "        x=top_venues[\"Total_Matches\"], \n",
    "        name=\"Total Matches\",\n",
    "        marker_color=\"DodgerBlue\",\n",
    "        orientation=\"h\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=top_venues[\"Match Venue (Stadium)\"], \n",
    "        x=top_venues[\"Wins\"], \n",
    "        name=\"Wins\",\n",
    "        marker_color=\"green\",\n",
    "        orientation=\"h\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=top_venues[\"Match Venue (Stadium)\"], \n",
    "        x=top_venues[\"Losses\"], \n",
    "        name=\"Losses\",\n",
    "        marker_color=\"red\",\n",
    "        orientation=\"h\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=top_venues[\"Match Venue (Stadium)\"], \n",
    "        x=top_venues[\"No_Result\"], \n",
    "        name=\"No Result Matches\",\n",
    "        marker_color=\"orange\",\n",
    "        orientation=\"h\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Top 10 Venues with Highest Win % for {team_name} (Minimum 5 matches on that venue)\",\n",
    "        xaxis_title=\"Count\",\n",
    "        yaxis_title=\"Venue\",\n",
    "        yaxis=dict(autorange=\"reversed\"),\n",
    "        barmode=\"group\",  # Grouped bars\n",
    "        legend_title=\"Match Stats\",\n",
    "        height=1200\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Plot Venue Stats\n",
    "plot_top_venues_by_win_percentage(\"South Africa\", final_venue_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training data\n",
    "training_data = []\n",
    "target = []\n",
    "\n",
    "for index, row in filtered_df_matches.iterrows():\n",
    "    team1 = row['Team1 Name']\n",
    "    team2 = row['Team2 Name']\n",
    "    venue = row['Match Venue (Stadium)']\n",
    "    winner = row['Match Winner']\n",
    "    \n",
    "    # Target encoding\n",
    "    if winner == team1:\n",
    "        target.append(0)  # Team1 wins\n",
    "    elif winner == team2:\n",
    "        target.append(1)  # Team2 wins\n",
    "    else:\n",
    "        target.append(2)  # No Result\n",
    "    \n",
    "    # Lookup matchup stats\n",
    "    matchup = matchup_stats[(matchup_stats['Team1'] == team1) & (matchup_stats['Team2'] == team2)]\n",
    "    if not matchup.empty:\n",
    "        t1_win_pct = matchup['Team1 Win %'].values[0]\n",
    "        t2_win_pct = matchup['Team2 Win %'].values[0]\n",
    "        no_result_pct = matchup['No Result %'].values[0]\n",
    "    else:\n",
    "        t1_win_pct, t2_win_pct, no_result_pct = 33.33, 33.33, 33.33\n",
    "    \n",
    "    # Lookup venue stats for Team1\n",
    "    venue_t1 = final_venue_stats[(final_venue_stats['Team'] == team1) & \n",
    "                                 (final_venue_stats['Match Venue (Stadium)'] == venue)]\n",
    "    if not venue_t1.empty:\n",
    "        t1_venue_win = venue_t1['Win %'].values[0]\n",
    "        t1_venue_no_result = venue_t1['No Result %'].values[0]\n",
    "        t1_venue_loss = venue_t1['Loss %'].values[0]\n",
    "    else:\n",
    "        t1_venue_win, t1_venue_no_result, t1_venue_loss = 33.33, 33.33, 33.33\n",
    "    \n",
    "    # Lookup venue stats for Team2\n",
    "    venue_t2 = final_venue_stats[(final_venue_stats['Team'] == team2) & \n",
    "                                 (final_venue_stats['Match Venue (Stadium)'] == venue)]\n",
    "    if not venue_t2.empty:\n",
    "        t2_venue_win = venue_t2['Win %'].values[0]\n",
    "        t2_venue_no_result = venue_t2['No Result %'].values[0]\n",
    "        t2_venue_loss = venue_t2['Loss %'].values[0]\n",
    "    else:\n",
    "        t2_venue_win, t2_venue_no_result, t2_venue_loss = 33.33, 33.33\n",
    "    \n",
    "    # Combine features\n",
    "    features = [t1_win_pct, t2_win_pct, no_result_pct, \n",
    "                t1_venue_win, t1_venue_no_result, t1_venue_loss,\n",
    "                t2_venue_win, t2_venue_no_result, t2_venue_loss]\n",
    "    training_data.append(features)\n",
    "\n",
    "# Convert to DataFrame\n",
    "training_df = pd.DataFrame(training_data, columns=[\n",
    "    'T1_Win_Pct', 'T2_Win_Pct', 'No_Result_Pct',\n",
    "    'T1_Venue_Win', 'T1_Venue_No_Result', 'T1_Venue_Loss',\n",
    "    'T2_Venue_Win', 'T2_Venue_No_Result', 'T2_Venue_Loss'\n",
    "])\n",
    "target = pd.Series(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Training Data:\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nTarget:\")\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_df, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate Random Forest\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate XGBoost\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
    "print(\"XGBoost Accuracy:\", xgb_accuracy)\n",
    "\n",
    "# Select the best model\n",
    "best_model = xgb_model if xgb_accuracy > rf_accuracy else rf_model\n",
    "best_accuracy = max(xgb_accuracy, rf_accuracy)\n",
    "print(\"Best Model:\", \"XGBoost\" if xgb_accuracy > rf_accuracy else \"Random Forest\")\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "# Random Forest with default parameters\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_cv_scores = cross_val_score(rf_model, training_df, target, cv=5, scoring='accuracy')\n",
    "print(\"Random Forest Cross-Validation Accuracy: \", rf_cv_scores.mean(), \"±\", rf_cv_scores.std())\n",
    "\n",
    "# XGBoost with default parameters\n",
    "try:\n",
    "    xgb_model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "    xgb_cv_scores = cross_val_score(xgb_model, training_df, target, cv=5, scoring='accuracy')\n",
    "    print(\"XGBoost Cross-Validation Accuracy: \", xgb_cv_scores.mean(), \"±\", xgb_cv_scores.std())\n",
    "except AttributeError as e:\n",
    "    print(\"Error with XGBoost and cross_val_score:\", e)\n",
    "    print(\"Falling back to manual cross-validation for XGBoost...\")\n",
    "    # Manual cross-validation as a fallback\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    xgb_scores = []\n",
    "    for train_idx, test_idx in kf.split(training_df):\n",
    "        X_train, X_test = training_df.iloc[train_idx], training_df.iloc[test_idx]\n",
    "        y_train, y_test = target.iloc[train_idx], target.iloc[test_idx]\n",
    "        xgb_model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        preds = xgb_model.predict(X_test)\n",
    "        score = accuracy_score(y_test, preds)\n",
    "        xgb_scores.append(score)\n",
    "    xgb_cv_scores = np.array(xgb_scores)\n",
    "    print(\"XGBoost Cross-Validation Accuracy (Manual): \", xgb_cv_scores.mean(), \"±\", xgb_cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "# Random Forest Grid Search\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "rf_grid_search.fit(training_df, target)\n",
    "print(\"Best Random Forest Parameters:\", rf_grid_search.best_params_)\n",
    "print(\"Best Random Forest CV Accuracy:\", rf_grid_search.best_score_)\n",
    "\n",
    "# XGBoost Grid Search\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.6, 0.8, 1.0]\n",
    "}\n",
    "xgb_grid_search = GridSearchCV(XGBClassifier(eval_metric='mlogloss', random_state=42), \n",
    "                               xgb_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "xgb_grid_search.fit(training_df, target)\n",
    "print(\"Best XGBoost Parameters:\", xgb_grid_search.best_params_)\n",
    "print(\"Best XGBoost CV Accuracy:\", xgb_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate Class Imbalance and Feature Quality\n",
    "\n",
    "# Check class distribution in target\n",
    "print(\"\\nClass Distribution in Target:\")\n",
    "print(target.value_counts(normalize=True))\n",
    "\n",
    "# Check feature quality\n",
    "print(\"\\nFeature Statistics:\")\n",
    "print(training_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model after tuning\n",
    "best_model = xgb_grid_search.best_estimator_ if xgb_grid_search.best_score_ > rf_grid_search.best_score_ else rf_grid_search.best_estimator_\n",
    "best_accuracy = max(xgb_grid_search.best_score_, rf_grid_search.best_score_)\n",
    "print(\"\\nBest Model After Tuning:\", \"XGBoost\" if xgb_grid_search.best_score_ > rf_grid_search.best_score_ else \"Random Forest\")\n",
    "print(\"Best Accuracy After Tuning:\", best_accuracy)\n",
    "\n",
    "# Save the best model for predictions\n",
    "final_model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_match_outcome(team1, team2, venue, model, matchup_stats, final_venue_stats):\n",
    "    # Extract features for the input\n",
    "    matchup = matchup_stats[(matchup_stats['Team1'] == team1) & (matchup_stats['Team2'] == team2)]\n",
    "    if not matchup.empty:\n",
    "        t1_win_pct = matchup['Team1 Win %'].values[0]\n",
    "        t2_win_pct = matchup['Team2 Win %'].values[0]\n",
    "        no_result_pct = matchup['No Result %'].values[0]\n",
    "    else:\n",
    "        t1_win_pct, t2_win_pct, no_result_pct = 33.33, 33.33, 33.33\n",
    "    \n",
    "    venue_t1 = final_venue_stats[(final_venue_stats['Team'] == team1) & \n",
    "                                 (final_venue_stats['Match Venue (Stadium)'] == venue)]\n",
    "    if not venue_t1.empty:\n",
    "        t1_venue_win = venue_t1['Win %'].values[0]\n",
    "        t1_venue_no_result = venue_t1['No Result %'].values[0]\n",
    "        t1_venue_loss = venue_t1['Loss %'].values[0]\n",
    "    else:\n",
    "        t1_venue_win, t1_venue_no_result, t1_venue_loss = 33.33, 33.33, 33.33\n",
    "    \n",
    "    venue_t2 = final_venue_stats[(final_venue_stats['Team'] == team2) & \n",
    "                                 (final_venue_stats['Match Venue (Stadium)'] == venue)]\n",
    "    if not venue_t2.empty:\n",
    "        t2_venue_win = venue_t2['Win %'].values[0]\n",
    "        t2_venue_no_result = venue_t2['No Result %'].values[0]\n",
    "        t2_venue_loss = venue_t2['Loss %'].values[0]\n",
    "    else:\n",
    "        t2_venue_win, t2_venue_no_result, t2_venue_loss = 33.33, 33.33\n",
    "    \n",
    "    # Combine features into a single row\n",
    "    features = np.array([[t1_win_pct, t2_win_pct, no_result_pct, \n",
    "                          t1_venue_win, t1_venue_no_result, t1_venue_loss,\n",
    "                          t2_venue_win, t2_venue_no_result, t2_venue_loss]])\n",
    "    \n",
    "    # Predict using the model\n",
    "    prediction = model.predict(features)[0]\n",
    "    \n",
    "    # Decode the prediction\n",
    "    if prediction == 0:\n",
    "        return team1\n",
    "    elif prediction == 1:\n",
    "        return team2\n",
    "    else:\n",
    "        return \"No Result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "team1 = \"South Africa\"\n",
    "team2 = \"New Zealand\"\n",
    "venue = \"Lord's\"\n",
    "predicted_winner = predict_match_outcome(team1, team2, venue, final_model, matchup_stats, final_venue_stats)\n",
    "print(f\"Predicted Winner for {team1} vs {team2} at {venue}: {predicted_winner}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Cross-Validation with Detailed Metrics\n",
    "print(\"Cross-Validation with Detailed Metrics for Final Model...\")\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "\n",
    "# Perform cross-validation with multiple metrics\n",
    "cv_results = cross_validate(final_model, training_df, target, cv=5, scoring=scoring, return_train_score=False)\n",
    "\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(\"Accuracy: \", cv_results['test_accuracy'].mean(), \"±\", cv_results['test_accuracy'].std())\n",
    "print(\"Precision (Macro): \", cv_results['test_precision_macro'].mean(), \"±\", cv_results['test_precision_macro'].std())\n",
    "print(\"Recall (Macro): \", cv_results['test_recall_macro'].mean(), \"±\", cv_results['test_recall_macro'].std())\n",
    "print(\"F1-Score (Macro): \", cv_results['test_f1_macro'].mean(), \"±\", cv_results['test_f1_macro'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Accuracy, Confusion Matrix, Precision, Recall, and F1-Score\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy on Test Set:\", accuracy)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "print(\"\\nPrecision, Recall, and F1-Score:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Team1', 'Team2', 'No Result']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
